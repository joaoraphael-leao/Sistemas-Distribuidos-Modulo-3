#!/usr/bin/env python3
"""
Chatbot Service - gRPC Server com Integra√ß√£o Gemini AI
Implementa√ß√£o otimizada e limpa
"""

import sys
import os
from dotenv import load_dotenv
import google.generativeai as gemini
import grpc
from concurrent import futures
import time

# Configura√ß√£o de ambiente
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env'))
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Imports gRPC
from grpc_services import services_pb2, services_pb2_grpc

# Configura√ß√£o Gemini AI
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
if GEMINI_API_KEY:
    gemini.configure(api_key=GEMINI_API_KEY)
    model = gemini.GenerativeModel("gemini-2.0-flash")
else:
    model = None
    print("‚ö†Ô∏è  GEMINI_API_KEY n√£o configurada - usando respostas simuladas")

class ChatbotServiceServicer(services_pb2_grpc.ChatbotServiceServicer):
    """Implementa√ß√£o otimizada do servi√ßo de Chatbot"""
    
    def GetStatus(self, request, context):
        """Status do servi√ßo"""
        ai_status = "com IA Gemini" if model else "modo simula√ß√£o"
        return services_pb2.StatusResponse(
            message=f"Chatbot Service ativo {ai_status}"
        )
    
    def ResolveDuvida(self, request, context):
        """Resolve d√∫vidas usando Gemini AI"""
        try:
            # Valida√ß√£o otimizada
            if not request.duvida or not request.aula_contexto:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Campos 'duvida' e 'aula_contexto' s√£o obrigat√≥rios")
                return services_pb2.ChatbotDuvidaResponse()
            
            # Processamento da d√∫vida
            resposta = self._process_question(request.duvida, request.aula_contexto)
            
            return services_pb2.ChatbotDuvidaResponse(resposta=resposta)
            
        except Exception as e:
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Erro interno: {str(e)}")
            return services_pb2.ChatbotDuvidaResponse()
    
    def RegisterMetrics(self, request, context):
        """Registra m√©tricas de intera√ß√£o"""
        try:
            insights_response = services_pb2.StatusResponse(
                message="üìä M√©tricas registradas com sucesso"
            )
            
            return services_pb2.RegisterMetricsResponse(
                message=f"M√©tricas da intera√ß√£o {request.id_interacao} processadas",
                id_interacao=request.id_interacao,
                insights_servico=insights_response
            )
        except Exception as e:
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f'Erro ao registrar m√©tricas: {str(e)}')
            return services_pb2.RegisterMetricsResponse()
    
    def _process_question(self, duvida, aula_contexto):
        """Processa a pergunta com IA ou simula√ß√£o"""
        if model:
            try:
                prompt = f"Contexto da aula: {aula_contexto}\n\nD√∫vida do estudante: {duvida}\n\nResponda de forma did√°tica e clara:"
                response = model.generate_content(prompt)
                return response.text
            except Exception as e:
                return f"‚ö†Ô∏è Erro na IA: {str(e)}\n\nResposta alternativa: Para '{duvida}' no contexto de '{aula_contexto}', recomendo consultar a documenta√ß√£o oficial e praticar com exemplos."
        else:
            # Modo simula√ß√£o otimizado
            return f"""üìö Resposta simulada para sua d√∫vida sobre '{duvida}':

No contexto de '{aula_contexto}', esta √© uma excelente pergunta! 

üí° Sugest√µes:
1. Consulte a documenta√ß√£o oficial
2. Pratique com exemplos simples
3. Use ambientes de desenvolvimento interativos

‚ö†Ô∏è Para respostas reais da IA, configure GEMINI_API_KEY no arquivo .env"""

def serve():
    """Inicia o servidor gRPC otimizado"""
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    services_pb2_grpc.add_ChatbotServiceServicer_to_server(ChatbotServiceServicer(), server)
    
    listen_addr = 'localhost:8082'
    server.add_insecure_port(listen_addr)
    
    print("Chatbot Service iniciando na porta 8082...")
    ai_info = "com Gemini AI" if model else "em modo simula√ß√£o"
    print(f"üß† IA Status: {ai_info}")
    
    server.start()
    
    try:
        while True:
            time.sleep(86400)
    except KeyboardInterrupt:
        print("\nParando Chatbot Service...")
        server.stop(0)

if __name__ == '__main__':
    serve()